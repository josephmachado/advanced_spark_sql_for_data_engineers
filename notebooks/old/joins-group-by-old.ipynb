{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38201b8e-5ec7-4e24-ad41-0011f8af3d56",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3232db-5bc3-4bae-ad6f-82c256dd7197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python ./generate_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003506d-f81b-4fa3-81d6-ab2032830009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Joins\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea2430-f3ef-4ba5-ad2b-be716c1eaffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop existing tables if they exist\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.customer\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.lineitem\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.nation\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.orders\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.part\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.partsupp\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.region\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS prod.db.supplier\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55dea4-ae8d-4add-ac6f-c5e56fbd5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables using Iceberg format\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.customer (\n",
    "  c_custkey    BIGINT,\n",
    "  c_name       STRING,\n",
    "  c_address    STRING,\n",
    "  c_nationkey  BIGINT,\n",
    "  c_phone      STRING,\n",
    "  c_acctbal    DECIMAL(15,2),\n",
    "  c_mktsegment STRING,\n",
    "  c_comment    STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.lineitem (\n",
    "  l_orderkey      BIGINT,\n",
    "  l_partkey       BIGINT,\n",
    "  l_suppkey       BIGINT,\n",
    "  l_linenumber    INT,\n",
    "  l_quantity      DECIMAL(15,2),\n",
    "  l_extendedprice DECIMAL(15,2),\n",
    "  l_discount      DECIMAL(15,2),\n",
    "  l_tax           DECIMAL(15,2),\n",
    "  l_returnflag    STRING,\n",
    "  l_linestatus    STRING,\n",
    "  l_shipdate      DATE,\n",
    "  l_commitdate    DATE,\n",
    "  l_receiptdate   DATE,\n",
    "  l_shipinstruct  STRING,\n",
    "  l_shipmode      STRING,\n",
    "  l_comment       STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.nation (\n",
    "  n_nationkey INT,\n",
    "  n_name      STRING,\n",
    "  n_regionkey INT,\n",
    "  n_comment   STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.orders (\n",
    "  o_orderkey      BIGINT,\n",
    "  o_custkey       BIGINT,\n",
    "  o_orderstatus   STRING,\n",
    "  o_totalprice    DECIMAL(15,2),\n",
    "  o_orderdate     DATE,\n",
    "  o_orderpriority STRING,\n",
    "  o_clerk         STRING,\n",
    "  o_shippriority  INT,\n",
    "  o_comment       STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.part (\n",
    "  p_partkey     BIGINT,\n",
    "  p_name        STRING,\n",
    "  p_mfgr        STRING,\n",
    "  p_brand       STRING,\n",
    "  p_type        STRING,\n",
    "  p_size        INT,\n",
    "  p_container   STRING,\n",
    "  p_retailprice DECIMAL(15,2),\n",
    "  p_comment     STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.partsupp (\n",
    "  ps_partkey    BIGINT,\n",
    "  ps_suppkey    BIGINT,\n",
    "  ps_availqty   INT,\n",
    "  ps_supplycost DECIMAL(15,2),\n",
    "  ps_comment    STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.region (\n",
    "  r_regionkey INT,\n",
    "  r_name      STRING,\n",
    "  r_comment   STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod.db.supplier (\n",
    "  s_suppkey   BIGINT,\n",
    "  s_name      STRING,\n",
    "  s_address   STRING,\n",
    "  s_nationkey BIGINT,\n",
    "  s_phone     STRING,\n",
    "  s_acctbal   DECIMAL(15,2),\n",
    "  s_comment   STRING\n",
    ") USING iceberg\n",
    "TBLPROPERTIES (\n",
    "  'format-version' = '2'\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a3645-00d8-4a31-94fb-fda1944beadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def upsert_data(data_name, data_path = Path('/home/iceberg/notebooks/notebooks/data')):\n",
    "    csv_path = data_path / f'{data_name}.csv'\n",
    "    print(f'Reading {data_name} data from {str(csv_path)}')\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").option(\"inferSchema\", \"true\").load(str(csv_path))\n",
    "    df.writeTo(f\"prod.db.{data_name}\").overwritePartitions()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fdc45-ed0e-49c7-a5bd-ac4b5781175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_data('customer')\n",
    "upsert_data('lineitem')\n",
    "upsert_data(\"nation\")\n",
    "upsert_data(\"orders\")\n",
    "upsert_data(\"part\")\n",
    "upsert_data(\"partsupp\")\n",
    "upsert_data(\"region\")\n",
    "upsert_data(\"supplier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c3927-7c33-4484-bc67-a18a8e282857",
   "metadata": {},
   "source": [
    "add data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fec966-c1a0-4a29-9525-063c355e040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select * from prod.db.customer limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc92ec-ef6f-45d7-980e-48f55e62b2ee",
   "metadata": {},
   "source": [
    "![Data Model](./images/tpch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1719f6c2-8b5b-410a-abd5-b38fce0866c0",
   "metadata": {},
   "source": [
    "## Facts & Dimensions\n",
    "\n",
    "1. `Fact` tables containing information about how dimensions interact with each other in real life. Example: An order fact is an interaction between a customer and a seller involving one or more products. E.g. `Lineitem` & `Orders`.\n",
    "2. `Dimension` tables store data for a business entity (e.g., customer, product, partner, etc). These tables describe the ‘who’ and ‘what’ types of questions. For example, which stores had the highest revenue yesterday? In this question, stores will be the dimension. E.g. `Customer`, `Supplier`\n",
    "\n",
    "The term analytical querying usually refers to aggregating numerical (spend, count, sum, avg) data from the fact table for specific dimension attribute(s) (e.g., name, nation, date, month) from the dimension tables.\n",
    "\n",
    "Some examples of analytical queries are\n",
    "1. Who are the top 10 suppliers (by totalprice) in the past year?\n",
    "2. What are the average sales per nation per year?\n",
    "3. How do customer market segments perform (sales) month-over-month?\n",
    "\n",
    "**Example**\n",
    "\n",
    "![Analytical query](./images/analytical_qry.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569bae01-04b2-46de-9ab3-641c757b793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- write analytical query here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09026663-0282-4efa-930d-a285b74697a4",
   "metadata": {},
   "source": [
    "## Joins are essential for creating dimension tables & reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc9dc4-9ccb-416a-865f-dc199f9445ca",
   "metadata": {},
   "source": [
    "### Creating dimension tables from normalized upstream tables\n",
    "\n",
    "- Multiple normalized tables from upstream are combines to form dimension table\n",
    "- Joins are also used to enrich fact tables with dimensional information\n",
    "\n",
    "add: image to create dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb9661-ad10-4760-8abe-f28539b53c0f",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Create customer dimension by creating customer + nation + region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd627fc-cc23-4c88-bef2-c00e81585edf",
   "metadata": {},
   "source": [
    "### Types of join & when to use them\n",
    "\n",
    "Join criteria refers to the columns used to join the tables. When joining tables, there is usually one table called the driver table to which other tables are joined.\n",
    "\n",
    "Depending on your use case, you may want to:\n",
    "\n",
    "1. Use a left join to get all data from the driver table, even when relevant data is missing from other tables.\n",
    "2. Use an inner join to retrieve only data that is present in all the tables in the join.\n",
    "3. Use an anti-join to retrieve data from the driver table that is not present in the table being joined to.\n",
    "4. Use a full outer join to get data in either one of the multiple joining tables. This type of join is typically used for data validation and to determine differences in data between the tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb1d69-ec57-4532-b541-08c455b7dd5a",
   "metadata": {},
   "source": [
    "### Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca9bb3-28e0-45b8-9710-6ec203265fad",
   "metadata": {},
   "source": [
    "### Joins lead to bad data if underlying data assumptions are incorrect\n",
    "\n",
    "1. Joining table(s) with multiple grains will lead to duplicated or partial data. It’s best to ensure that your table(s) have a single grain before joining them.\n",
    "2. If the tables you are joining do not have complete data, your joins will produce partial or NULL data points. For e.g., if you are joining a customer’s personal details table with their payment information and the payment information for that customer has not yet arrived in the warehouse, you will receive NULL for this information.\n",
    "3. Joins on columns with NULLs. NULLs represent the absence of data, and as such, joins on NULL = NULL will not work. Ensure that you coalesce NULLs to a hardcoded value before joining (if that’s what you intend to do).\n",
    "4. Complex join criteria and join criteria that require transformation functions are typically indicative of a poor underlying data model. Try to solve this by making changes to the tables in the join.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0284db62-aa43-41e9-a79f-be5df015fe0f",
   "metadata": {},
   "source": [
    "## Group by represents the creation of metrics for analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ac1f5-18e2-4a5d-9a80-a64fc193da48",
   "metadata": {},
   "source": [
    "### Group by enables humans to understand data quickly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db8e27-1030-4d00-b187-bb5b841cce4e",
   "metadata": {},
   "source": [
    "### Go beyond standard aggregate functions.\n",
    "1. Standard agg: min/max/sum/avg/count\n",
    "2. Statistical agg: Functions like correlation, sampling, standard deviation, skew, etc\n",
    "3. Collection agg: Functions to combine values into nested data types, e.g., array_agg, collect_set, etc\n",
    "4. Approximation agg: Functions that are fast by sacrificing accuracy, e.g., approx_distinct, approx_most_frequent\n",
    "5. Convenience agg: Functions that make common usages easier, e.g., count_if, bool_or, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354b652-8ac1-436f-98ec-67d44c2edfc5",
   "metadata": {},
   "source": [
    "### Underlying data model and types need to be correct for group by to work as expected\n",
    "\n",
    "1. If you are grouping by multiple columns or using Group by to remove duplicates, this usually indicates a problem with your underlying data model\n",
    "2. For the columns on which you want to run aggregation functions, ensure that they are of the correct data type.\n",
    "3. Ensure that the columns that you are aggregating are additive. For example, you cannot aggregate percentages; instead, you must aggregate the numerator and denominator separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acac74e-6048-4e74-8228-454cc580ba55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
