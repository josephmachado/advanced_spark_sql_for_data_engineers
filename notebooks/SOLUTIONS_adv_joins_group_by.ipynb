{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e7e536-da58-4819-8812-3a9e99f9ea2d",
   "metadata": {},
   "source": [
    "# Spark SQL Workshop: Advanced join & group by techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58ed16-4cdd-4c3c-83f9-6b7ec83c68be",
   "metadata": {},
   "source": [
    "## Logistics \n",
    "\n",
    "### Date & Time\n",
    "**June 21st, 2025**  \n",
    "1:00 PM - 2:00 PM EST (10:00 AM - 11:00 AM PST)\n",
    "\n",
    "### What You Will Learn\n",
    "- How to use **JOINs** to validate data and identify underlying data issues\n",
    "- How to use advanced aggregation functions & check data quality with **GROUP BY** \n",
    "\n",
    "### Who This Workshop Is For\n",
    "\n",
    "**Prequisites:**\n",
    "- SQL basics, especially JOIN & GROUP BY basics ([see basics here](./basics.ipynb))\n",
    "- Basic understanding of **[fact and dimension tables](https://www.startdataengineering.com/post/advanced-sql/#4-data-modeling--data-flow)**\n",
    "- GitHub codespaces or Docker compose (if running locally)\n",
    "    \n",
    "**Perfect for:**\n",
    "- People with some experience in SQL\n",
    "- People who work with SQL regularly\n",
    "\n",
    "**Not suitable for:**\n",
    "- People who don't know SQL basics, especially JOIN & GROUP BY basics ([see basics here](./basics.ipynb))\n",
    "- People looking for topics other than advanced JOIN and GROUP BY techniques\n",
    "\n",
    "### How to Join\n",
    "- **Format:** YouTube live workshop with hands-on coding\n",
    "- **Participation:** You are expected to code along\n",
    "- **Interaction:** Live Q&A session included\n",
    "- **Practice:** Exercises provided\n",
    "\n",
    "### Workshop Link\n",
    "\n",
    "**[YouTube live link](https://www.youtube.com/watch?v=OPBhvZOq7oo)**\n",
    "\n",
    "### Feedback\n",
    "Feedback form link (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0a561-b750-495c-b570-e74c7ca2a38e",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a80054-51f7-497e-a4b3-ffc9a9bcec47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python ./generate_data.py\n",
    "python ./run_ddl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96686b88-9083-46eb-9938-f517be0fab4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!jupyter labextension install jupyterlab-mermaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d04a7-bc0e-44fc-b8be-7d8e36c92dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32129ccc-b2a7-4119-9acd-49cf976bc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "use prod.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1df8d3-1c86-4a2a-93dd-677940cc5948",
   "metadata": {},
   "source": [
    "## [Quick refresher] Facts & Dimensions\n",
    "\n",
    "1. `Fact` tables containing information about how dimensions interact with each other in real life. Example: An order fact is an interaction between a customer and a seller involving one or more products. E.g. `Lineitem` & `Orders`.\n",
    "2. `Dimension` tables store data for a business entity (e.g., customer, product, partner, etc). These tables describe the ‘who’ and ‘what’ types of questions. For example, which stores had the highest revenue yesterday? In this question, stores will be the dimension. E.g. `Customer`, `Supplier`\n",
    "\n",
    "The term analytical querying usually refers to aggregating numerical (spend, count, sum, avg) data from the fact table for specific dimension attribute(s) (e.g., name, nation, date, month) from the dimension tables.\n",
    "\n",
    "Some examples of analytical queries are\n",
    "1. Who are the top 10 suppliers (by totalprice) in the past year?\n",
    "2. What are the average sales per nation per year?\n",
    "3. How do customer market segments perform (sales) month-over-month?\n",
    "\n",
    "**Example**\n",
    "\n",
    "![Analytical query](./images/analytical_qry.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f66258-437c-4014-b687-02ade186569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "    YEAR(o.o_orderdate) as order_year,\n",
    "    c.c_name,\n",
    "    AVG(o.o_totalprice) as avg_order_price\n",
    "FROM orders o\n",
    "LEFT JOIN customer c ON o.o_custkey = c.c_custkey\n",
    "GROUP BY YEAR(o.o_orderdate), c.c_custkey, c.c_name\n",
    "ORDER BY 1 desc, c_custkey\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf1133-4021-416a-a7ec-87eb606f9cdb",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph A[\"Orders (Fact Table) - Wider\"]\n",
    "        A1[\"o_custkey: 1001 | o_orderdate: 2023-01-15 | o_totalprice: 75000.00\"]\n",
    "        A2[\"o_custkey: 1002 | o_orderdate: 2023-02-20 | o_totalprice: 120000.00\"]\n",
    "        A3[\"o_custkey: 1001 | o_orderdate: 2023-03-10 | o_totalprice: 95000.00\"]\n",
    "        A4[\"o_custkey: 1003 | o_orderdate: 2023-04-05 | o_totalprice: 85000.00\"]\n",
    "        A5[\"o_custkey: 9999 | o_orderdate: 2023-05-12 | o_totalprice: 50000.00\"]\n",
    "    end\n",
    "    \n",
    "    subgraph B[\"Customer (Dimension Table)\"]\n",
    "        B1[\"c_custkey: 1001 | c_name: John Smith\"]\n",
    "        B2[\"c_custkey: 1002 | c_name: Jane Doe\"]\n",
    "        B3[\"c_custkey: 1003 | c_name: Bob Wilson\"]\n",
    "    end\n",
    "    \n",
    "    subgraph C[\"Result\"]\n",
    "        C1[\"order_year: 2023 | c_name: John Smith | avg_order_price: 85000.00\"]\n",
    "        C2[\"order_year: 2023 | c_name: Jane Doe | avg_order_price: 120000.00\"]\n",
    "        C3[\"order_year: 2023 | c_name: Bob Wilson | avg_order_price: 85000.00\"]\n",
    "        C4[\"order_year: 2023 | c_name: NULL | avg_order_price: 50000.00\"]\n",
    "    end\n",
    "    \n",
    "    A1 -.->|matches| B1\n",
    "    A2 -.->|matches| B2\n",
    "    A3 -.->|matches| B1\n",
    "    A4 -.->|matches| B3\n",
    "    A5 -.->|no match| C4\n",
    "    \n",
    "    B1 -->|contributes to| C1\n",
    "    B2 -->|contributes to| C2\n",
    "    B3 -->|contributes to| C3\n",
    "    \n",
    "    style A fill:#e74c3c,stroke:#c0392b,color:#fff,stroke-width:3px\n",
    "    style B fill:#3498db,stroke:#2980b9,color:#fff,stroke-width:2px\n",
    "    style C fill:#27ae60,stroke:#229954,color:#fff,stroke-width:2px\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8644127-0d35-49d9-be70-d8d8cb48644c",
   "metadata": {},
   "source": [
    "## [Joins] can be used to validate data and identify underlying data issues\n",
    "\n",
    "- While `joins` are typically used to combine tables, they can also be used to inspect data and get data diff.\n",
    "\n",
    "- When joining tables, there is usually one table called the `driver/base` table to which other tables are joined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e25e16-f16f-466d-a3b6-0c999c7c59f4",
   "metadata": {},
   "source": [
    "### Find data in a table that is not part of another table with `anti join`\n",
    "\n",
    "- When you need to get rows that are in one table but not in another, use `anti join`\n",
    "\n",
    "- You can get the rows from the left table that does not have any matches from the right table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca273baf-8824-4601-8a36-cb0532686f30",
   "metadata": {},
   "source": [
    "#### Exercise ( 5 min )\n",
    "1. In the below query get all the data from `orders` CTE what are not in `lineitem` CTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913188a7-4103-48c8-b410-53c3dcb41475",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph A[\"Orders Table\"]\n",
    "        A1[\"`**o_orderkey | o_custkey**\n",
    "        001 | 1001\n",
    "        002 | 1002\n",
    "        003 | 1003\n",
    "        004 | 1004\n",
    "        005 | 1005`\"]\n",
    "    end\n",
    "    \n",
    "    subgraph B[\"LineItem Table\"]\n",
    "        B1[\"`**l_orderkey | l_partkey**\n",
    "        001 | 2001\n",
    "        003 | 2003\n",
    "        005 | 2004`\"]\n",
    "    end\n",
    "    \n",
    "    subgraph C[\"Result\"]\n",
    "        C1[\"`**o_orderkey | o_custkey**\n",
    "        002 | 1002\n",
    "        004 | 1004`\"]\n",
    "    end\n",
    "    \n",
    "    A1 -->|ANTI JOIN| C1\n",
    "    B1 -.->|\"ON o_orderkey = l_orderkey\"| C1\n",
    "    \n",
    "    style A fill:#3498db,stroke:#2980b9,color:#fff\n",
    "    style B fill:#27ae60,stroke:#229954,color:#fff\n",
    "    style C fill:#e74c3c,stroke:#c0392b,color:#fff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b60e6-f138-4af8-a6dc-943b699a1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH orders AS (\n",
    " SELECT 001 as o_orderkey, 1001 as o_custkey\n",
    " UNION ALL\n",
    " SELECT 002 as o_orderkey, 1002 as o_custkey\n",
    " UNION ALL\n",
    " SELECT 003 as o_orderkey, 1003 as o_custkey\n",
    " UNION ALL\n",
    " SELECT 004 as o_orderkey, 1004 as o_custkey\n",
    " UNION ALL\n",
    " SELECT 005 as o_orderkey, 1005 as o_custkey\n",
    "),\n",
    "lineitem AS (\n",
    " SELECT 001 as l_orderkey, 2001 as l_partkey\n",
    " UNION ALL\n",
    " SELECT 003 as l_orderkey, 2003 as l_partkey\n",
    " UNION ALL\n",
    " SELECT 005 as l_orderkey, 2004 as l_partkey\n",
    ")\n",
    "SELECT o.*\n",
    "FROM orders o\n",
    "ANTI JOIN lineitem l ON o.o_orderkey = l.l_orderkey\n",
    "-- Alternative approach; when you don't have anti join\n",
    "-- LEFT JOIN lineitem l ON o.o_orderkey = l.l_orderkey WHERE l.l_orderkey IS NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2915962-7394-458c-bac5-48f6cf8ab91e",
   "metadata": {},
   "source": [
    "    \n",
    "### Find data in a table that is closest in time to another table with `asof join` (not available in Spark)\n",
    "\n",
    "- When you need to get the row that is closest in time to the current row\n",
    "\n",
    "- Usually used when you need to get the \"latest\" price, or state from a fact table. Not really used to join dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c29b80-7af5-485f-a3f0-699f31c5b90d",
   "metadata": {},
   "source": [
    "#### Exercise ( 5 min )\n",
    "1. In the below query get the `symbol, company, listing_date` from `stock` CTE and for the stock get their price as of asof the `listing_date`.\n",
    "\n",
    "*Note* Assume the `price_tracker` CTE is a fact table where every change to the stocks are added to (typically this is in ms, but for simplicity we keep it at a day level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4d832c-92b3-4cb2-850b-159ab770189a",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph A[\"Stock Table\"]\n",
    "        A1[\"AAPL | Apple Inc. | 2024-01-01\"]\n",
    "        A2[\"GOOGL | Alphabet Inc. | 2024-01-15\"]\n",
    "        A3[\"MSFT | Microsoft Corp. | 2024-02-01\"]\n",
    "    end\n",
    "    \n",
    "    subgraph B[\"Price Tracker Table\"]\n",
    "        B1[\"AAPL | 150.00 | 2024-01-10\"]\n",
    "        B2[\"AAPL | 155.00 | 2024-01-20\"]\n",
    "        B3[\"GOOGL | 2800.00 | 2024-01-25\"]\n",
    "        B4[\"GOOGL | 2850.00 | 2024-02-05\"]\n",
    "        B5[\"MSFT | 400.00 | 2024-02-10\"]\n",
    "    end\n",
    "    \n",
    "    subgraph C[\"Result\"]\n",
    "        C1[\"AAPL | Apple Inc. | 155.00 | 2024-01-20\"]\n",
    "        C2[\"GOOGL | Alphabet Inc. | 2850.00 | 2024-02-05\"]\n",
    "        C3[\"MSFT | Microsoft Corp. | 400.00 | 2024-02-10\"]\n",
    "    end\n",
    "    \n",
    "    A1 -.->|matches| B1\n",
    "    A1 -->|latest match| B2\n",
    "    A2 -.->|matches| B3\n",
    "    A2 -->|latest match| B4\n",
    "    A3 -->|matches| B5\n",
    "    \n",
    "    B2 -->|result| C1\n",
    "    B4 -->|result| C2\n",
    "    B5 -->|result| C3\n",
    "    \n",
    "    style A fill:#3498db,stroke:#2980b9,color:#fff\n",
    "    style B fill:#27ae60,stroke:#229954,color:#fff\n",
    "    style C fill:#e74c3c,stroke:#c0392b,color:#fff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addb601-c88c-4f24-9480-d6e8ed8176ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH stock AS (\n",
    " SELECT 'AAPL' as symbol, 'Apple Inc.' as company, '2024-01-01' as listing_date\n",
    " UNION ALL\n",
    " SELECT 'GOOGL' as symbol, 'Alphabet Inc.' as company, '2024-01-15' as listing_date\n",
    " UNION ALL\n",
    " SELECT 'MSFT' as symbol, 'Microsoft Corp.' as company, '2024-02-01' as listing_date\n",
    "),\n",
    "price_tracker AS (\n",
    " SELECT 'AAPL' as symbol, 150.00 as price, '2024-01-10' as price_date\n",
    " UNION ALL\n",
    " SELECT 'AAPL' as symbol, 155.00 as price, '2024-01-20' as price_date -- this is the latest price for apple and will be picked\n",
    " UNION ALL\n",
    " SELECT 'GOOGL' as symbol, 2800.00 as price, '2024-01-25' as price_date\n",
    " UNION ALL\n",
    " SELECT 'GOOGL' as symbol, 2850.00 as price, '2024-02-05' as price_date -- this is the latest price for google and will be picked\n",
    " UNION ALL\n",
    " SELECT 'MSFT' as symbol, 400.00 as price, '2024-02-10' as price_date -- this is the latest price for microsoft and will be picked\n",
    "),\n",
    "ranked_prices AS (\n",
    "  SELECT s.symbol, s.company, s.listing_date, p.price, p.price_date,\n",
    "         ROW_NUMBER() OVER (PARTITION BY s.symbol, s.listing_date \n",
    "                           ORDER BY p.price_date DESC) as rn\n",
    "  FROM stock s\n",
    "  JOIN price_tracker p ON s.symbol = p.symbol \n",
    "  WHERE s.listing_date <= p.price_date\n",
    ")\n",
    "SELECT symbol, company, listing_date, price, price_date\n",
    "FROM ranked_prices\n",
    "WHERE rn = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d92f3db-342c-426d-967f-23948592aea2",
   "metadata": {},
   "source": [
    "**Hint:** Get all the prices for a symbol and filter to the latest one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88957e-9381-4a00-ac61-63302aecb402",
   "metadata": {},
   "source": [
    "\n",
    "### Joins are used to validate referential integrity (aka are `foreign key` relationships valid)\n",
    "\n",
    "- In a data warehouse some tables are created sooner than others\n",
    "\n",
    "- When you join a quick table with a slow table you will loose data\n",
    "\n",
    "- For example, if your orders data arrives much quicker than customer data your joins will either produce nulls (left join) or not be included in the output (inner joins)\n",
    "\n",
    "- Usually an `UNKNOWN` catch all is used, you can also re-run the pipeline to reconcile when the slow data lands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f91d8-cc6b-4575-846a-c6b04aef5f0e",
   "metadata": {},
   "source": [
    "#### Exercise ( 10 min )\n",
    "\n",
    "1. Assume you have to join orders (loaded into warehouse in 5 minutes) and customer (loaded into the warehouse every 6h) table; how do you ensure that the results of your join is **complete**? \n",
    "\n",
    "    **Hint**: Start by defining what complete means.\n",
    "\n",
    "2. What will you do if you find the table(s) are incomplete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a5a87-d40d-48d7-a1af-3f9203ea438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH latest_orders AS (\n",
    " SELECT * FROM orders\n",
    " UNION ALL\n",
    " SELECT \n",
    "   9999999 as o_orderkey,\n",
    "   8888888 as o_custkey,\n",
    "   'O' as o_orderstatus,\n",
    "   1500000.00 as o_totalprice,\n",
    "   '2024-06-14' as o_orderdate,\n",
    "   '1-URGENT' as o_orderpriority,\n",
    "   'Clerk#000000999' as o_clerk,\n",
    "   0 as o_shippriority,\n",
    "   'New order for non-existent customer' as o_comment\n",
    ")\n",
    "SELECT o.*\n",
    "    , c.* -- What would you do with these NULLs?\n",
    "FROM latest_orders o\n",
    "LEFT JOIN customer c ON o.o_custkey = c.c_custkey WHERE c.c_custkey IS NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a95225-35c6-4706-a503-51944568da0e",
   "metadata": {},
   "source": [
    "**Discussion**:\n",
    "  \n",
    "Typically the fact tables arrive faster than dimensions (not raw data, but modelled dimension tables). And due to this the fact tables may have dimension ids that have not been loaded into the dimension table or have not been updated in the dimension table.\n",
    "\n",
    "Depending on the use case there are 3 main ways of dealing with this scenario:\n",
    "\n",
    "1. Left join dimension data to fact table and fill up NULLs with `UNKNOWN` or similar when reporting.\n",
    "2. Do an inner join to only keep data that is fully available.\n",
    "3. Reprocess the join pipeline multiple times so initially you will have `UNKNOWN` and on a future re-run you will have the dimension data and use this to overwrite existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eca369-83a0-4f7b-9e7d-d14d923eb4b4",
   "metadata": {},
   "source": [
    "\n",
    "### Common data issues that create bad outputs when joining\n",
    "\n",
    "- Ensure that your table(s) have a single grain before joining them.\n",
    "\n",
    "- Handle slow and fast data joins based on use case\n",
    "\n",
    "- Be careful if your join keys have NULLs, NULL != NULL\n",
    "                                \n",
    "- Be mindful of applying functions in join criteria, they can impact performance significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810ee05-3b13-4d23-94fb-f959a353abd9",
   "metadata": {},
   "source": [
    "## [Group bys] can be used for more than reporting\n",
    "\n",
    "- Quickly check distribution of dimensions (date, state, etc)\n",
    "\n",
    "- Check unique key constraints, most warehouse allow you to define PK, but don't enforce them\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26db404-fee3-4e31-929c-c14d9fc62a75",
   "metadata": {},
   "source": [
    "#### Exercise ( 5 min )\n",
    "\n",
    "Do you think the data is representative of real world from the customer numbers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c92da2-604b-4c48-bdf8-765d7faac8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select n.n_name as nation_name\n",
    "    , count(*) as num_customers\n",
    "    from customer c\n",
    "    left join nation n \n",
    "    on c.c_nationkey = n.n_nationkey\n",
    "group by n.n_name\n",
    "order by num_customers desc\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6039938f-9a1c-4d8d-8f13-b81ecc68ba42",
   "metadata": {},
   "source": [
    "The above results don't seem to make sense, as we cannot generally expect orders from `china` and other countries be around the similar number. This would raise red flags in a real life scenario.\n",
    "\n",
    "**However** we use a tool that uses normal distribution to create fake data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e9d6a-73c4-4196-a4ec-f18ad3dbf255",
   "metadata": {},
   "source": [
    "#### Exercise ( 5 min ) \n",
    "\n",
    "How would you use `group by` to check that the c_custkey column in the customer table is unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d29b4f-a92f-4cd7-82ca-413acfa3e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select c_custkey\n",
    ", count(*) as cnt\n",
    "from customer \n",
    "group by 1\n",
    "having cnt > 1\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e0979-4468-4e99-8bc6-88651ad2a52f",
   "metadata": {},
   "source": [
    "### Aggregation functions beyond the standard count/min/max/avg/sum\n",
    "\n",
    "- Statistical agg: Functions like correlation, sampling, standard deviation, skew, etc\n",
    "\n",
    "- Collection agg: Functions to combine values into nested data types, e.g., array_agg, collect_set, etc\n",
    "\n",
    "- Approximation agg: Functions that are fast by sacrificing accuracy, e.g., approx_distinct, approx_most_frequent\n",
    "\n",
    "- Convenience agg: Functions that make common usages easier, e.g., count_if, bool_or, etc\n",
    "\n",
    "- ROLL UPs, CUBE, GROUPING SETS are short hand versions of GROUP BYs typically used for reporting\n",
    "\n",
    "While you can try to use your own logic to replicate some of the above functions, in-built functions are generally stable and well tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7244a-b291-43e3-9a76-c6a2a9ff3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select \n",
    "    year(o_orderdate) as yr\n",
    "    , sum(case when o_orderpriority = '5-LOW' then 1 else 0 end) as num_low_orders\n",
    "    , count_if(o_orderpriority = '5-LOW') as num_low_orders_easy -- Convenience agg\n",
    "\n",
    "from orders\n",
    "group by 1\n",
    "order by 1 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945898d5-5de7-4457-9c0b-9c9955796961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT l_orderkey\n",
    "   , collect_list(l_linenumber) as line_number\n",
    "   , collect_list(struct(\n",
    "        l_linenumber as line_number,\n",
    "        l_quantity as quantity, \n",
    "        l_extendedprice as price\n",
    "    )) as line_details -- Structured output\n",
    "FROM lineitem\n",
    "GROUP BY 1\n",
    "ORDER BY l_orderkey\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb198f-7551-4f14-8b0f-70a79ec2d2fe",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph A[\"LineItem Table (Input)\"]\n",
    "        A1[\"orderkey: 1 | linenumber: 1 | quantity: 17 | price: 26734.03\"]\n",
    "        A2[\"orderkey: 1 | linenumber: 2 | quantity: 36 | price: 57191.40\"]\n",
    "        A3[\"orderkey: 1 | linenumber: 3 | quantity: 8 | price: 14254.80\"]\n",
    "        A4[\"orderkey: 2 | linenumber: 1 | quantity: 38 | price: 39447.04\"]\n",
    "        A5[\"orderkey: 3 | linenumber: 1 | quantity: 45 | price: 47301.30\"]\n",
    "        A6[\"orderkey: 3 | linenumber: 2 | quantity: 49 | price: 69947.99\"]\n",
    "    end\n",
    "    \n",
    "    subgraph C[\"Result (Aggregated)\"]\n",
    "        C1[\"orderkey: 1<br/>line_numbers: [1,2,3,4,5,6]<br/>line_details: [struct(1,17,26734), struct(2,36,57191), ...]\"]\n",
    "        C2[\"orderkey: 2<br/>line_numbers: [1]<br/>line_details: [struct(1,38,39447)]\"]\n",
    "        C3[\"orderkey: 3<br/>line_numbers: [1,2,3,4,5,6]<br/>line_details: [struct(1,45,47301), struct(2,49,69947), ...]\"]\n",
    "    end\n",
    "    \n",
    "    A1 -.-> C1\n",
    "    A2 -.-> C1\n",
    "    A3 -.-> C1\n",
    "    A4 --> C2\n",
    "    A5 -.-> C3\n",
    "    A6 -.-> C3\n",
    "    \n",
    "    style A fill:#3498db,stroke:#2980b9,color:#fff\n",
    "    style C fill:#27ae60,stroke:#229954,color:#fff\n",
    "    \n",
    "    style A fill:#3498db,stroke:#2980b9,color:#fff\n",
    "    style C fill:#27ae60,stroke:#229954,color:#fff\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f166f-235e-4d33-81bf-c63294493418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH order_details AS (\n",
    "  SELECT l_orderkey\n",
    "     , collect_list(l_linenumber) as line_number\n",
    "     , collect_list(struct(\n",
    "          l_linenumber as line_number,\n",
    "          l_quantity as quantity, \n",
    "          l_extendedprice as price\n",
    "      )) as line_details\n",
    "  FROM lineitem\n",
    "  GROUP BY 1\n",
    ")\n",
    "SELECT \n",
    "    l_orderkey,\n",
    "    exploded_detail.line_number,\n",
    "    exploded_detail.quantity,\n",
    "    exploded_detail.price\n",
    "    -- , explode(line_number) as individual_line_number\n",
    "FROM order_details\n",
    "LATERAL VIEW explode(line_details) t AS exploded_detail\n",
    "    ORDER BY l_orderkey\n",
    "LIMIT 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd74323-04e7-4e68-b1e1-cc38634abe53",
   "metadata": {},
   "source": [
    "#### Exercise ( 5 min )\n",
    "\n",
    "Try the above query by uncommenting this `, explode(line_number)` line, what do you think is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de90702-460d-4895-835f-c5406cb55212",
   "metadata": {},
   "source": [
    "### Group by variations for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72f9e6-0fec-40e3-9f34-c739d3187009",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW sales AS\n",
    "SELECT 'North' as region, 'Electronics' as category, 100 as amount\n",
    "UNION ALL\n",
    "SELECT 'North' as region, 'Clothing' as category, 50 as amount\n",
    "UNION ALL\n",
    "SELECT 'South' as region, 'Electronics' as category, 80 as amount\n",
    "UNION ALL\n",
    "SELECT 'South' as region, 'Clothing' as category, 70 as amount;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7e493-ba1b-4cce-8cb2-ad399d09059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- ROLLUP: Hierarchical aggregation (region -> category -> total)\n",
    "SELECT region, category, SUM(amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY ROLLUP(region, category)\n",
    "ORDER BY region, category;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360dcd0-743b-46dc-a05f-c204d56cec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- CUBE: All possible combinations\n",
    "SELECT region, category, SUM(amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY CUBE(region, category)\n",
    "ORDER BY region, category;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1c0c2-26c2-427f-b265-871292b38f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- GROUPING SETS: Custom combinations\n",
    "SELECT region, category, SUM(amount) as total_sales\n",
    "FROM sales\n",
    "GROUP BY GROUPING SETS (\n",
    " (region, category),  -- detailed\n",
    " (region),           -- by region only\n",
    " ()                  -- grand total only\n",
    ")\n",
    "ORDER BY region, category;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d89dd-3c50-4884-9cdc-b900f83a8247",
   "metadata": {},
   "source": [
    "### Gotchas when doing group bys: duplication, incorrect data types, additive/non-additive numbers, etc\n",
    "\n",
    "- Are you using Group by to remove duplicates, this usually indicates a problem with your underlying data model\n",
    "\n",
    "- Ensure that the numbers you are aggregating on are of the right data typs (e.g. number stored as string, .)\n",
    "\n",
    "- Be mindful of additive and non-additive numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee5063-c28b-4d15-a1be-2ed14daa7043",
   "metadata": {},
   "source": [
    "#### Exercise ( 5 min )\n",
    "\n",
    "Inspect the below query, what is wrong with the logic correct? \n",
    "\n",
    "How would you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd065ae-6b01-46ff-bae0-97357f44cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- CTE: Unique suppliers per day\n",
    "WITH daily_suppliers AS (\n",
    " SELECT \n",
    "   DATE(l_shipdate) as ship_date,\n",
    "   COUNT(DISTINCT l_suppkey) as daily_unique_suppliers\n",
    " FROM lineitem\n",
    " GROUP BY DATE(l_shipdate)\n",
    ")\n",
    "SELECT \n",
    " YEAR(d.ship_date) as ship_year,\n",
    " SUM(d.daily_unique_suppliers) as yearly_total\n",
    "FROM daily_suppliers d\n",
    "GROUP BY YEAR(d.ship_date)\n",
    "ORDER BY ship_year;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60ea7f-4e2f-4825-8945-f64268e0021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- CTE: Unique suppliers per day\n",
    "WITH daily_suppliers AS (\n",
    " SELECT \n",
    "   DATE(l_shipdate) as ship_date,\n",
    "   COUNT(DISTINCT l_suppkey) as daily_unique_suppliers\n",
    " FROM lineitem\n",
    " GROUP BY DATE(l_shipdate)\n",
    "),\n",
    "\n",
    "-- Unique suppliers per year (CORRECT way)\n",
    "yearly_suppliers AS (\n",
    " SELECT \n",
    "   YEAR(l_shipdate) as ship_year,\n",
    "   COUNT(DISTINCT l_suppkey) as yearly_unique_suppliers\n",
    " FROM lineitem\n",
    " GROUP BY YEAR(l_shipdate)\n",
    ")\n",
    "\n",
    "-- WRONG: Trying to sum daily unique suppliers to get yearly total\n",
    "SELECT \n",
    " YEAR(d.ship_date) as ship_year,\n",
    " SUM(d.daily_unique_suppliers) as wrong_yearly_total,  -- This is WRONG!\n",
    " y.yearly_unique_suppliers as correct_yearly_total\n",
    "FROM daily_suppliers d\n",
    "JOIN yearly_suppliers y ON YEAR(d.ship_date) = y.ship_year\n",
    "GROUP BY YEAR(d.ship_date), y.yearly_unique_suppliers\n",
    "ORDER BY ship_year;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b53d7-0960-4116-afbb-714ea4b2c189",
   "metadata": {},
   "source": [
    "## Recommended reading\n",
    "\n",
    "1. [SQL for data engineers](https://www.startdataengineering.com/post/improve-sql-skills-de/)\n",
    "2. [SQL or Python for data processing](https://www.startdataengineering.com/post/sql-v-python/)\n",
    "3. [dbt tutorial](https://www.startdataengineering.com/post/dbt-data-build-tool-tutorial/)\n",
    "4. [Build a data project with step-by-step instructions](https://www.startdataengineering.com/post/de-proj-step-by-step/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
